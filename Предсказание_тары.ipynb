{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sultan477/DataScience/blob/main/%D0%9F%D1%80%D0%B5%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%B0%D0%BD%D0%B8%D0%B5_%D1%82%D0%B0%D1%80%D1%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "10e98d98",
      "metadata": {
        "id": "10e98d98"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mlp\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24968648",
      "metadata": {
        "id": "24968648"
      },
      "source": [
        "### Базовое знакомство с данными"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df70cd6b",
      "metadata": {
        "id": "df70cd6b",
        "outputId": "ec581bb7-b414-433e-e281-4f178962bbcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>tare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Котлеты МЛМ из говядины 335г</td>\n",
              "      <td>коробка</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Победа Вкуса конфеты Мишки в лесу 250г(КФ ПОБЕ...</td>\n",
              "      <td>коробка</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ТВОРОГ (ЮНИМИЛК) \"ПРОСТОКВАШИНО\" ЗЕРНЕНЫЙ 130Г...</td>\n",
              "      <td>стаканчик</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Сыр Плавленый Веселый Молочник с Грибами 190г ...</td>\n",
              "      <td>контейнер</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Жевательный мармелад Маша и медведь  буквы 100г</td>\n",
              "      <td>пакет без формы</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               name             tare\n",
              "0   0                       Котлеты МЛМ из говядины 335г          коробка\n",
              "1   1  Победа Вкуса конфеты Мишки в лесу 250г(КФ ПОБЕ...          коробка\n",
              "2   2  ТВОРОГ (ЮНИМИЛК) \"ПРОСТОКВАШИНО\" ЗЕРНЕНЫЙ 130Г...        стаканчик\n",
              "3   3  Сыр Плавленый Веселый Молочник с Грибами 190г ...        контейнер\n",
              "4   4    Жевательный мармелад Маша и медведь  буквы 100г  пакет без формы"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/train.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb70531",
      "metadata": {
        "id": "1fb70531"
      },
      "source": [
        "Какие уникальные значения принимает таргет, есть ли дизбаланс?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b590d1cc",
      "metadata": {
        "id": "b590d1cc",
        "outputId": "9a1cbd1f-6bbe-464e-ea59-9a2d8a882a21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "пакет без формы                   9028\n",
              "бутылка                           7474\n",
              "коробка                           4196\n",
              "пакет прямоугольный               3501\n",
              "обертка                           3217\n",
              "банка неметаллическая             2238\n",
              "стаканчик                         2070\n",
              "банка металлическая               1837\n",
              "вакуумная упаковка                1071\n",
              "усадочная упаковка                 993\n",
              "контейнер                          884\n",
              "пачка                              691\n",
              "лоток                              628\n",
              "туба                               589\n",
              "гофрокороб                         419\n",
              "колбасная оболочка                 396\n",
              "тортница                           324\n",
              "без упаковки                       322\n",
              "упаковка с газовым наполнением     289\n",
              "ведро                              253\n",
              "ячеистая упаковка                  228\n",
              "Name: tare, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"tare\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b1bc93",
      "metadata": {
        "id": "01b1bc93"
      },
      "source": [
        "Разделим выборку на обучающую и тестовую"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da8d5d1",
      "metadata": {
        "id": "6da8d5d1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(\n",
        "    df,\n",
        "    test_size=0.25,\n",
        "    stratify=df[\"tare\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446a6e32",
      "metadata": {
        "id": "446a6e32"
      },
      "source": [
        "Используем стратифицированное разделение в силу дизбаланса классов.\n",
        "\n",
        "Делаем мы этого для того, чтобы избежать случайного *выпадания* какого-либо из видов тары. Например, если на трейне к нам не попадут товары, запакованные в тубу, то и на тесте мы их не сможем верно классифицировать. От этого будет страдать обобщающая способность модели. Стратификация позволяет сделать распределение таргетов в трейне и тесте таким, каким оно примерно является в общей совокупности.\n",
        "\n",
        "Убедимся, что действительно и в трейне, и в тесте схожая доля каждой тары!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8e3c8a",
      "metadata": {
        "id": "9c8e3c8a",
        "outputId": "c87d0573-ef64-4ec3-ba7e-ec94d04db8fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Доля в трейне</th>\n",
              "      <th>Доля в тесте</th>\n",
              "      <th>Абсолютная разница</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>пакет без формы</th>\n",
              "      <td>0.222102</td>\n",
              "      <td>0.222102</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>бутылка</th>\n",
              "      <td>0.183855</td>\n",
              "      <td>0.183920</td>\n",
              "      <td>0.000066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>коробка</th>\n",
              "      <td>0.103228</td>\n",
              "      <td>0.103228</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>пакет прямоугольный</th>\n",
              "      <td>0.086138</td>\n",
              "      <td>0.086105</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>обертка</th>\n",
              "      <td>0.079151</td>\n",
              "      <td>0.079118</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>банка неметаллическая</th>\n",
              "      <td>0.055042</td>\n",
              "      <td>0.055107</td>\n",
              "      <td>0.000066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>стаканчик</th>\n",
              "      <td>0.050909</td>\n",
              "      <td>0.050974</td>\n",
              "      <td>0.000066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>банка металлическая</th>\n",
              "      <td>0.045201</td>\n",
              "      <td>0.045168</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>вакуумная упаковка</th>\n",
              "      <td>0.026340</td>\n",
              "      <td>0.026373</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>усадочная упаковка</th>\n",
              "      <td>0.024437</td>\n",
              "      <td>0.024405</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>контейнер</th>\n",
              "      <td>0.021748</td>\n",
              "      <td>0.021748</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>пачка</th>\n",
              "      <td>0.016991</td>\n",
              "      <td>0.017024</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>лоток</th>\n",
              "      <td>0.015450</td>\n",
              "      <td>0.015450</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>туба</th>\n",
              "      <td>0.014498</td>\n",
              "      <td>0.014466</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>гофрокороб</th>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.010333</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>колбасная оболочка</th>\n",
              "      <td>0.009742</td>\n",
              "      <td>0.009742</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>тортница</th>\n",
              "      <td>0.007971</td>\n",
              "      <td>0.007971</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>без упаковки</th>\n",
              "      <td>0.007938</td>\n",
              "      <td>0.007872</td>\n",
              "      <td>0.000066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>упаковка с газовым наполнением</th>\n",
              "      <td>0.007118</td>\n",
              "      <td>0.007085</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ведро</th>\n",
              "      <td>0.006232</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ячеистая упаковка</th>\n",
              "      <td>0.005609</td>\n",
              "      <td>0.005609</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Доля в трейне  Доля в тесте  \\\n",
              "пакет без формы                      0.222102      0.222102   \n",
              "бутылка                              0.183855      0.183920   \n",
              "коробка                              0.103228      0.103228   \n",
              "пакет прямоугольный                  0.086138      0.086105   \n",
              "обертка                              0.079151      0.079118   \n",
              "банка неметаллическая                0.055042      0.055107   \n",
              "стаканчик                            0.050909      0.050974   \n",
              "банка металлическая                  0.045201      0.045168   \n",
              "вакуумная упаковка                   0.026340      0.026373   \n",
              "усадочная упаковка                   0.024437      0.024405   \n",
              "контейнер                            0.021748      0.021748   \n",
              "пачка                                0.016991      0.017024   \n",
              "лоток                                0.015450      0.015450   \n",
              "туба                                 0.014498      0.014466   \n",
              "гофрокороб                           0.010300      0.010333   \n",
              "колбасная оболочка                   0.009742      0.009742   \n",
              "тортница                             0.007971      0.007971   \n",
              "без упаковки                         0.007938      0.007872   \n",
              "упаковка с газовым наполнением       0.007118      0.007085   \n",
              "ведро                                0.006232      0.006200   \n",
              "ячеистая упаковка                    0.005609      0.005609   \n",
              "\n",
              "                                Абсолютная разница  \n",
              "пакет без формы                           0.000000  \n",
              "бутылка                                   0.000066  \n",
              "коробка                                   0.000000  \n",
              "пакет прямоугольный                       0.000033  \n",
              "обертка                                   0.000033  \n",
              "банка неметаллическая                     0.000066  \n",
              "стаканчик                                 0.000066  \n",
              "банка металлическая                       0.000033  \n",
              "вакуумная упаковка                        0.000033  \n",
              "усадочная упаковка                        0.000033  \n",
              "контейнер                                 0.000000  \n",
              "пачка                                     0.000033  \n",
              "лоток                                     0.000000  \n",
              "туба                                      0.000033  \n",
              "гофрокороб                                0.000033  \n",
              "колбасная оболочка                        0.000000  \n",
              "тортница                                  0.000000  \n",
              "без упаковки                              0.000066  \n",
              "упаковка с газовым наполнением            0.000033  \n",
              "ведро                                     0.000033  \n",
              "ячеистая упаковка                         0.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_shares = df_train[\"tare\"].value_counts() / df_train.shape[0]\n",
        "test_shares = df_test[\"tare\"].value_counts() / df_test.shape[0]\n",
        "\n",
        "to_compare = pd.concat((train_shares, test_shares), axis=1)\n",
        "to_compare.columns = ['Доля в трейне', 'Доля в тесте']\n",
        "to_compare['Абсолютная разница'] = (to_compare[\"Доля в трейне\"] - \\\n",
        "                                    to_compare[\"Доля в тесте\"]).abs()\n",
        "\n",
        "to_compare"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c9c95e6",
      "metadata": {
        "id": "7c9c95e6"
      },
      "source": [
        "### Построим базовую модель в качестве бейзлайна. TF-IDF + KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ef69231",
      "metadata": {
        "id": "1ef69231"
      },
      "source": [
        "Преобразуем наименования товаров с помощью `tf-idf`, взглянем на результат и ровно на нем обучим простейший `KNN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44564856",
      "metadata": {
        "id": "44564856"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29da0994",
      "metadata": {
        "id": "29da0994"
      },
      "source": [
        "Импортируем классический `TfidfVectorizer` из `sklearn` и обозначим класс за переменную `tfidf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8875aa50",
      "metadata": {
        "id": "8875aa50"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f10b026a",
      "metadata": {
        "id": "f10b026a"
      },
      "source": [
        "Произведем `TfIdf` преобразование на первых 5 наименованиях.\n",
        "\n",
        "Метод `fit_transform` возвращает `sparse matrix`.\n",
        "\n",
        "Применим метод `toarray`, чтобы получить данные типа `array`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3711d294",
      "metadata": {
        "id": "3711d294",
        "outputId": "c0167197-ea5c-44ea-b0f9-1391c3917744"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.4472136 , 0.        , 0.        , 0.        , 0.4472136 ,\n",
              "        0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.30151134, 0.30151134,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.30151134,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.30151134, 0.        , 0.30151134, 0.30151134, 0.        ,\n",
              "        0.        , 0.        , 0.30151134, 0.        , 0.        ,\n",
              "        0.        , 0.60302269, 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.4472136 , 0.        , 0.4472136 ,\n",
              "        0.4472136 ],\n",
              "       [0.        , 0.        , 0.37796447, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.37796447, 0.37796447, 0.        ,\n",
              "        0.        , 0.37796447, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
              "        0.37796447, 0.        , 0.        , 0.37796447, 0.        ,\n",
              "        0.        ],\n",
              "       [0.40824829, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.40824829, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.40824829,\n",
              "        0.40824829, 0.40824829, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_data = (\n",
        "    tfidf\n",
        "    .fit_transform(df[\"name\"].head())\n",
        "    .toarray()\n",
        ")\n",
        "\n",
        "tfidf_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deff70ca",
      "metadata": {
        "id": "deff70ca"
      },
      "source": [
        "Отправим полученный `array` в `DataFrame`, чтобы убедиться в корректности работы метода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312be627",
      "metadata": {
        "id": "312be627",
        "outputId": "06fe01b7-20c7-496f-96fd-14029c74a681"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>100г</th>\n",
              "      <th>130гр</th>\n",
              "      <th>190г</th>\n",
              "      <th>20</th>\n",
              "      <th>250г</th>\n",
              "      <th>335г</th>\n",
              "      <th>буквы</th>\n",
              "      <th>ванна</th>\n",
              "      <th>веселый</th>\n",
              "      <th>вкуса</th>\n",
              "      <th>...</th>\n",
              "      <th>медведь</th>\n",
              "      <th>мишки</th>\n",
              "      <th>млм</th>\n",
              "      <th>молочник</th>\n",
              "      <th>плавленый</th>\n",
              "      <th>победа</th>\n",
              "      <th>простоквашино</th>\n",
              "      <th>сыр</th>\n",
              "      <th>творог</th>\n",
              "      <th>юнимилк</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301511</td>\n",
              "      <td>0.301511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301511</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.603023</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.447214</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       100г     130гр      190г        20      250г      335г     буквы  \\\n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.447214  0.000000   \n",
              "1  0.000000  0.000000  0.000000  0.301511  0.301511  0.000000  0.000000   \n",
              "2  0.000000  0.447214  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3  0.000000  0.000000  0.377964  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.408248  0.000000  0.000000  0.000000  0.000000  0.000000  0.408248   \n",
              "\n",
              "      ванна   веселый     вкуса  ...   медведь     мишки       млм  молочник  \\\n",
              "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.447214  0.000000   \n",
              "1  0.000000  0.000000  0.301511  ...  0.000000  0.301511  0.000000  0.000000   \n",
              "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "3  0.377964  0.377964  0.000000  ...  0.000000  0.000000  0.000000  0.377964   \n",
              "4  0.000000  0.000000  0.000000  ...  0.408248  0.000000  0.000000  0.000000   \n",
              "\n",
              "   плавленый    победа  простоквашино       сыр    творог   юнимилк  \n",
              "0   0.000000  0.000000       0.000000  0.000000  0.000000  0.000000  \n",
              "1   0.000000  0.603023       0.000000  0.000000  0.000000  0.000000  \n",
              "2   0.000000  0.000000       0.447214  0.000000  0.447214  0.447214  \n",
              "3   0.377964  0.000000       0.000000  0.377964  0.000000  0.000000  \n",
              "4   0.000000  0.000000       0.000000  0.000000  0.000000  0.000000  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_data_df = pd.DataFrame(\n",
        "    tfidf_data,\n",
        "    index=df[\"name\"].head().index,\n",
        "    columns=tfidf.get_feature_names_out()\n",
        ")\n",
        "\n",
        "tfidf_data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a2970c",
      "metadata": {
        "id": "f5a2970c"
      },
      "source": [
        "Pipeline сам умеет применять `fit_transform`, поэтому можно так компактно записать процесс `tf-idf` преобразования и обучения на нем модели.\n",
        "\n",
        "Нет необходимости переводить `array` в `DataFrame`, так как модели из `sklearn` умеют отлично работать с np массивами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6333f57",
      "metadata": {
        "id": "f6333f57"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce7d5b0",
      "metadata": {
        "id": "bce7d5b0"
      },
      "source": [
        "Построим `Pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc75e46c",
      "metadata": {
        "id": "fc75e46c"
      },
      "outputs": [],
      "source": [
        "pipeline_baseline = Pipeline(\n",
        "    [\n",
        "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
        "        ('default_KNN', KNeighborsClassifier())\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd9687a",
      "metadata": {
        "id": "cdd9687a"
      },
      "source": [
        "Зафитим модель тренировочными данными и замерим качество на трейне и тесте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917b58db",
      "metadata": {
        "id": "917b58db",
        "outputId": "728770a2-dd6a-4800-f4c1-2c724d78570e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy на тренировочной выборке составило 0.898\n",
            "Accuracy на тестовой выборке составило 0.837\n"
          ]
        }
      ],
      "source": [
        "pipeline_baseline.fit(\n",
        "    df_train[\"name\"],\n",
        "    df_train[\"tare\"]\n",
        ")\n",
        "\n",
        "train_preds = pipeline_baseline.predict(df_train[\"name\"])\n",
        "train_accuracy = np.mean(train_preds == df_train[\"tare\"].values)\n",
        "\n",
        "test_preds = pipeline_baseline.predict(df_test[\"name\"])\n",
        "test_accuracy = np.mean(test_preds == df_test[\"tare\"].values)\n",
        "\n",
        "print(f\"Accuracy на тренировочной выборке составило {np.round(train_accuracy, decimals=3)}\")\n",
        "print(f\"Accuracy на тестовой выборке составило {np.round(test_accuracy, decimals=3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4927870",
      "metadata": {
        "id": "e4927870"
      },
      "source": [
        "Accuracy даже с учетом дисбаланса классов (максимальная доля около 22%) оказывается достаточно высоким.\n",
        "\n",
        "Есть смысль повалидироваться на гиперпараметрах модели, так как она может в итоге оказаться финально лучшей.\n",
        "\n",
        "В качестве параметров для валидации выберем:\n",
        "\n",
        "- Количество соседей (`n`)\n",
        "- Способ взвешивания соседей (`weights`)\n",
        "- Параметр p метрики Минковского (`p`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63eed7a5",
      "metadata": {
        "id": "63eed7a5",
        "outputId": "b2193945-18a3-4ee4-a7d0-4c789a212eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 18 candidates, totalling 18 fits\n",
            "[CV 1/1; 1/18] START default_KNN__n_neighbors=5, default_KNN__p=2, default_KNN__weights=uniform\n",
            "[CV 1/1; 1/18] END default_KNN__n_neighbors=5, default_KNN__p=2, default_KNN__weights=uniform;, score=(train=0.898, test=0.837) total time=   6.8s\n",
            "[CV 1/1; 2/18] START default_KNN__n_neighbors=5, default_KNN__p=2, default_KNN__weights=distance\n",
            "[CV 1/1; 2/18] END default_KNN__n_neighbors=5, default_KNN__p=2, default_KNN__weights=distance;, score=(train=0.998, test=0.850) total time=   6.5s\n",
            "[CV 1/1; 3/18] START default_KNN__n_neighbors=5, default_KNN__p=2, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>\n",
            "[CV 1/1; 3/18] END default_KNN__n_neighbors=5, default_KNN__p=2, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>;, score=(train=0.974, test=0.854) total time=   6.5s\n",
            "[CV 1/1; 4/18] START default_KNN__n_neighbors=5, default_KNN__p=1, default_KNN__weights=uniform\n",
            "[CV 1/1; 4/18] END default_KNN__n_neighbors=5, default_KNN__p=1, default_KNN__weights=uniform;, score=(train=0.898, test=0.830) total time=   7.0s\n",
            "[CV 1/1; 5/18] START default_KNN__n_neighbors=5, default_KNN__p=1, default_KNN__weights=distance\n",
            "[CV 1/1; 5/18] END default_KNN__n_neighbors=5, default_KNN__p=1, default_KNN__weights=distance;, score=(train=0.998, test=0.852) total time=   6.6s\n",
            "[CV 1/1; 6/18] START default_KNN__n_neighbors=5, default_KNN__p=1, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>\n",
            "[CV 1/1; 6/18] END default_KNN__n_neighbors=5, default_KNN__p=1, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>;, score=(train=0.998, test=0.860) total time=   6.9s\n",
            "[CV 1/1; 7/18] START default_KNN__n_neighbors=10, default_KNN__p=2, default_KNN__weights=uniform\n",
            "[CV 1/1; 7/18] END default_KNN__n_neighbors=10, default_KNN__p=2, default_KNN__weights=uniform;, score=(train=0.855, test=0.810) total time=   6.8s\n",
            "[CV 1/1; 8/18] START default_KNN__n_neighbors=10, default_KNN__p=2, default_KNN__weights=distance\n",
            "[CV 1/1; 8/18] END default_KNN__n_neighbors=10, default_KNN__p=2, default_KNN__weights=distance;, score=(train=0.998, test=0.834) total time=   6.3s\n",
            "[CV 1/1; 9/18] START default_KNN__n_neighbors=10, default_KNN__p=2, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>\n",
            "[CV 1/1; 9/18] END default_KNN__n_neighbors=10, default_KNN__p=2, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>;, score=(train=0.941, test=0.839) total time=   7.2s\n",
            "[CV 1/1; 10/18] START default_KNN__n_neighbors=10, default_KNN__p=1, default_KNN__weights=uniform\n",
            "[CV 1/1; 10/18] END default_KNN__n_neighbors=10, default_KNN__p=1, default_KNN__weights=uniform;, score=(train=0.856, test=0.809) total time=   7.2s\n",
            "[CV 1/1; 11/18] START default_KNN__n_neighbors=10, default_KNN__p=1, default_KNN__weights=distance\n",
            "[CV 1/1; 11/18] END default_KNN__n_neighbors=10, default_KNN__p=1, default_KNN__weights=distance;, score=(train=0.998, test=0.840) total time=   7.3s\n",
            "[CV 1/1; 12/18] START default_KNN__n_neighbors=10, default_KNN__p=1, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>\n",
            "[CV 1/1; 12/18] END default_KNN__n_neighbors=10, default_KNN__p=1, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>;, score=(train=0.997, test=0.864) total time=   6.6s\n",
            "[CV 1/1; 13/18] START default_KNN__n_neighbors=20, default_KNN__p=2, default_KNN__weights=uniform\n",
            "[CV 1/1; 13/18] END default_KNN__n_neighbors=20, default_KNN__p=2, default_KNN__weights=uniform;, score=(train=0.807, test=0.776) total time=   8.7s\n",
            "[CV 1/1; 14/18] START default_KNN__n_neighbors=20, default_KNN__p=2, default_KNN__weights=distance\n",
            "[CV 1/1; 14/18] END default_KNN__n_neighbors=20, default_KNN__p=2, default_KNN__weights=distance;, score=(train=0.998, test=0.800) total time=   5.9s\n",
            "[CV 1/1; 15/18] START default_KNN__n_neighbors=20, default_KNN__p=2, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>\n",
            "[CV 1/1; 15/18] END default_KNN__n_neighbors=20, default_KNN__p=2, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>;, score=(train=0.890, test=0.808) total time=   7.4s\n",
            "[CV 1/1; 16/18] START default_KNN__n_neighbors=20, default_KNN__p=1, default_KNN__weights=uniform\n",
            "[CV 1/1; 16/18] END default_KNN__n_neighbors=20, default_KNN__p=1, default_KNN__weights=uniform;, score=(train=0.805, test=0.776) total time=   7.8s\n",
            "[CV 1/1; 17/18] START default_KNN__n_neighbors=20, default_KNN__p=1, default_KNN__weights=distance\n",
            "[CV 1/1; 17/18] END default_KNN__n_neighbors=20, default_KNN__p=1, default_KNN__weights=distance;, score=(train=0.998, test=0.812) total time=   7.5s\n",
            "[CV 1/1; 18/18] START default_KNN__n_neighbors=20, default_KNN__p=1, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>\n",
            "[CV 1/1; 18/18] END default_KNN__n_neighbors=20, default_KNN__p=1, default_KNN__weights=<function gaussian_kernel at 0x1362e7e50>;, score=(train=0.997, test=0.865) total time=   6.9s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=[([12619, 22985, 9368, 20471, 29219, 836, 21930, 21138, 20511,\n",
              "                   38467, 29387, 32935, 25247, 12920, 11015, 27662, 21173,\n",
              "                   23394, 35592, 31049, 19076, 12119, 20934, 14739, 19282, 7561,\n",
              "                   21490, 20145, 17016, 35524, ...],\n",
              "                  [36160, 16249, 38619, 7152, 33356, 3329, 34481, 31220, 1680,\n",
              "                   36759, 38990, 14533, 38448, 25028, 2886, 1393, 31922, 15256,\n",
              "                   30898, 28602, 31556, 28276, 3955, 18086, 12963, 3912, 19638,\n",
              "                   23368, 26803, 13988, ...])],\n",
              "             estimator=Pipeline(steps=[('tfidf_vectorizer', TfidfVectorizer()),\n",
              "                                       ('default_KNN',\n",
              "                                        KNeighborsClassifier())]),\n",
              "             param_grid={'default_KNN__n_neighbors': [5, 10, 20],\n",
              "                         'default_KNN__p': (2, 1),\n",
              "                         'default_KNN__weights': ['uniform', 'distance',\n",
              "                                                  <function gaussian_kernel at 0x1362e7e50>]},\n",
              "             return_train_score=True, scoring='accuracy', verbose=10)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def gaussian_kernel(distances, h=1):\n",
        "        return np.exp(- distances**2 / h**2)\n",
        "\n",
        "parameters_grid = {\n",
        "    'default_KNN__n_neighbors': [5, 10, 20],\n",
        "    'default_KNN__weights': ['uniform', 'distance', gaussian_kernel],\n",
        "    'default_KNN__p': (2, 1),\n",
        "}\n",
        "\n",
        "custom_cv = [(df_train.index.to_list(), df_test.index.to_list())]\n",
        "\n",
        "search_baseline = GridSearchCV(\n",
        "    pipeline_baseline,\n",
        "    parameters_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=custom_cv,\n",
        "    verbose=10,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "search_baseline.fit(df[\"name\"], df[\"tare\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77c48dd",
      "metadata": {
        "id": "b77c48dd"
      },
      "source": [
        "Взглянем на лучшую модель и ее качество."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f3a179",
      "metadata": {
        "id": "18f3a179",
        "outputId": "deba5c5f-8b75-47d3-e383-e050a939f532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameter (CV score=0.86459):\n",
            "{'default_KNN__n_neighbors': 20, 'default_KNN__p': 1, 'default_KNN__weights': <function gaussian_kernel at 0x1362e7e50>}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best parameter (CV score={search_baseline.best_score_:.5f}):\")\n",
        "print(search_baseline.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee458e7",
      "metadata": {
        "id": "eee458e7",
        "outputId": "ffd843e7-3925-44ee-e98b-b0be5cb3f9c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf_vectorizer', TfidfVectorizer()),\n",
              "                ('default_KNN',\n",
              "                 KNeighborsClassifier(n_neighbors=20, p=1,\n",
              "                                      weights=<function gaussian_kernel at 0x1362e7e50>))])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_baseline.set_params(**search_baseline.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f672b98",
      "metadata": {
        "id": "3f672b98"
      },
      "source": [
        "Дополнительно проверим качество лучшей модели (помимо логов `gridsearch`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "865cdfb6",
      "metadata": {
        "id": "865cdfb6",
        "outputId": "536e1845-9ca8-4c98-829f-d2d1298954c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy на тренировочной выборке составило 0.997\n",
            "Accuracy на тестовой выборке составило 0.865\n"
          ]
        }
      ],
      "source": [
        "pipeline_baseline.fit(\n",
        "    df_train[\"name\"],\n",
        "    df_train[\"tare\"]\n",
        ")\n",
        "\n",
        "train_preds = pipeline_baseline.predict(df_train[\"name\"])\n",
        "train_accuracy = np.mean(train_preds == df_train[\"tare\"].values)\n",
        "\n",
        "test_preds = pipeline_baseline.predict(df_test[\"name\"])\n",
        "test_accuracy = np.mean(test_preds == df_test[\"tare\"].values)\n",
        "\n",
        "print(f\"Accuracy на тренировочной выборке составило {np.round(train_accuracy, decimals=3)}\")\n",
        "print(f\"Accuracy на тестовой выборке составило {np.round(test_accuracy, decimals=3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "905885d4",
      "metadata": {
        "id": "905885d4"
      },
      "source": [
        "Качество на трейне выросло, стало почти идеальным +0.099\n",
        "\n",
        "Качество на тесте тоже выросло, хоть и не так сильно +0.029\n",
        "\n",
        "Очевидно в глаза бросается переобучение, поэтому есть смысл протестировать модели, менее склонные к нему."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0690141a",
      "metadata": {
        "id": "0690141a"
      },
      "source": [
        "### SVM, RandomForest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22fcf2f4",
      "metadata": {
        "id": "22fcf2f4"
      },
      "source": [
        "Построим пайплайны с тремя предложенными к рассмотрению моделями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e77a4b3",
      "metadata": {
        "id": "6e77a4b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "pipeline_svm = Pipeline(\n",
        "    [\n",
        "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
        "        ('SVC', SVC())\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline_rf = Pipeline(\n",
        "    [\n",
        "        ('tfidf_vectorizer', TfidfVectorizer()),\n",
        "        ('RF', RandomForestClassifier())\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87de0099",
      "metadata": {
        "id": "87de0099"
      },
      "source": [
        "Найдем лучшие гиперпараметры для `SVM` и оценим качество на трейне/тесте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b02d34b",
      "metadata": {
        "id": "7b02d34b",
        "outputId": "f9de0573-6751-4f09-c4be-db499a929d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy на тренировочной выборке составило 0.997\n",
            "Accuracy на тестовой выборке составило 0.874\n"
          ]
        }
      ],
      "source": [
        "svm_parameters_grid = {\n",
        "    'SVC__C': [1, 0.5, 3],\n",
        "    'SVC__kernel': ['linear', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "search_svm = GridSearchCV(\n",
        "    pipeline_svm,\n",
        "    svm_parameters_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=custom_cv,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "search_svm.fit(df[\"name\"], df[\"tare\"])\n",
        "\n",
        "pipeline_svm.set_params(**search_svm.best_params_)\n",
        "\n",
        "pipeline_svm.fit(\n",
        "    df_train[\"name\"],\n",
        "    df_train[\"tare\"]\n",
        ")\n",
        "\n",
        "train_preds = pipeline_svm.predict(df_train[\"name\"])\n",
        "train_accuracy = np.mean(train_preds == df_train[\"tare\"].values)\n",
        "\n",
        "test_preds = pipeline_svm.predict(df_test[\"name\"])\n",
        "test_accuracy = np.mean(test_preds == df_test[\"tare\"].values)\n",
        "\n",
        "print(f\"Accuracy на тренировочной выборке составило {np.round(train_accuracy, decimals=3)}\")\n",
        "print(f\"Accuracy на тестовой выборке составило {np.round(test_accuracy, decimals=3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "538a86d3",
      "metadata": {
        "id": "538a86d3"
      },
      "source": [
        "Качество на тесте выросло +0.01 по сравнению с лучшим KNN\n",
        "\n",
        "Возможно, стоило лучше поиграться с гиперпараметрыми, например, с `penalty`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b05b3b6d",
      "metadata": {
        "id": "b05b3b6d"
      },
      "source": [
        "Найдем лучшие гиперпараметры для `RandomForest` и оценим качество на трейне/тесте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e9224cb",
      "metadata": {
        "id": "0e9224cb",
        "outputId": "3d4413db-7a4d-4eda-9f16-660bf3e9f144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy на тренировочной выборке составило 0.998\n",
            "Accuracy на тестовой выборке составило 0.831\n"
          ]
        }
      ],
      "source": [
        "rf_parameters_grid = {\n",
        "    'RF__n_estimators': [10, 100, 200],\n",
        "    'RF__max_depth': [5, 15, 30, None]\n",
        "}\n",
        "\n",
        "search_rf = GridSearchCV(\n",
        "    pipeline_rf,\n",
        "    rf_parameters_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=custom_cv,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "search_rf.fit(df[\"name\"], df[\"tare\"])\n",
        "\n",
        "pipeline_rf.set_params(**search_rf.best_params_)\n",
        "\n",
        "pipeline_rf.fit(\n",
        "    df_train[\"name\"],\n",
        "    df_train[\"tare\"]\n",
        ")\n",
        "\n",
        "train_preds = pipeline_rf.predict(df_train[\"name\"])\n",
        "train_accuracy = np.mean(train_preds == df_train[\"tare\"].values)\n",
        "\n",
        "test_preds = pipeline_rf.predict(df_test[\"name\"])\n",
        "test_accuracy = np.mean(test_preds == df_test[\"tare\"].values)\n",
        "\n",
        "print(f\"Accuracy на тренировочной выборке составило {np.round(train_accuracy, decimals=3)}\")\n",
        "print(f\"Accuracy на тестовой выборке составило {np.round(test_accuracy, decimals=3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3eb7d5",
      "metadata": {
        "id": "5c3eb7d5"
      },
      "source": [
        "Случайный лес справляется хуже."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf85a50",
      "metadata": {
        "id": "daf85a50"
      },
      "source": [
        "Неудивительно, что модели обучаются очень долго, так как tf-idf по большому корпусу текстов содержит $n \\cdot m$ элементов, где $n$ - количество текстов, $m$ - количество уникальных слов."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91eba9e7",
      "metadata": {
        "id": "91eba9e7"
      },
      "source": [
        "### Гипотеза: сузив tf-idf пространство, можно получить лучшее качество SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70aa3e0c",
      "metadata": {
        "id": "70aa3e0c"
      },
      "source": [
        "Идея следующая: сузим пространство с помощью PCA преобразования, выделим в новом пространстве несколько кластеров (скажем, 15 штук: хотя на этом параметре можно еще повалидироваться), после чего каждый объект подменим вектором его расстояний до центра из каждого кластера.\n",
        "\n",
        "У такого сложного преобразования есть некоторая интерпретация: мы выделяем наиболее важные компоненты каждого объекта, находим некоторые \"общий паттерны\" по аналогии с жанрами фильмов, после чего получаем каждый объект как смесь каждого \"жанра\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c146cc",
      "metadata": {
        "id": "18c146cc"
      },
      "source": [
        "Так как нам важна обобщающая способность, алгоритмы преобразований (PCA + Kmeans) будем фитить исключительно в тренировочную часть.\n",
        "\n",
        "Начнем с выделения оригинальных векторов tf-idf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a272913",
      "metadata": {
        "id": "6a272913"
      },
      "outputs": [],
      "source": [
        "tfidf_ = TfidfVectorizer()\n",
        "tfidf_.fit(df_train[\"name\"])\n",
        "\n",
        "tfidf_array_train = (\n",
        "    tfidf_\n",
        "    .transform(df_train[\"name\"])\n",
        "    .toarray()\n",
        ")\n",
        "\n",
        "tfidf_array_test = (\n",
        "    tfidf_\n",
        "    .transform(df_test[\"name\"])\n",
        "    .toarray()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de30f1ca",
      "metadata": {
        "id": "de30f1ca"
      },
      "source": [
        "Выделим 20 главных компонент. Не забудем центрировать данные на всякий случай, хоть sklearn и делает это за нас."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d641ed8",
      "metadata": {
        "id": "5d641ed8"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "centered_train = tfidf_array_train - tfidf_array_train.mean()\n",
        "centered_test = tfidf_array_test - tfidf_array_test.mean()\n",
        "\n",
        "pca = PCA(n_components=20)\n",
        "pca.fit(centered_train)\n",
        "\n",
        "pca_train = pca.transform(centered_train)\n",
        "pca_test = pca.transform(centered_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cade3d48",
      "metadata": {
        "id": "cade3d48"
      },
      "source": [
        "Выделим 15 кластеров в новом полученном множестве (объекты те же, только признаков теперь всего 20) и замерим расстояние от каждого объекта до центра каждого кластера."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948bbfd7",
      "metadata": {
        "id": "948bbfd7",
        "outputId": "ccffbd98-8ac4-40d4-edda-7623f5ff196a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DistanceTo1thCluster</th>\n",
              "      <th>DistanceTo2thCluster</th>\n",
              "      <th>DistanceTo3thCluster</th>\n",
              "      <th>DistanceTo4thCluster</th>\n",
              "      <th>DistanceTo5thCluster</th>\n",
              "      <th>DistanceTo6thCluster</th>\n",
              "      <th>DistanceTo7thCluster</th>\n",
              "      <th>DistanceTo8thCluster</th>\n",
              "      <th>DistanceTo9thCluster</th>\n",
              "      <th>DistanceTo10thCluster</th>\n",
              "      <th>DistanceTo11thCluster</th>\n",
              "      <th>DistanceTo12thCluster</th>\n",
              "      <th>DistanceTo13thCluster</th>\n",
              "      <th>DistanceTo14thCluster</th>\n",
              "      <th>DistanceTo15thCluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.333051</td>\n",
              "      <td>0.508755</td>\n",
              "      <td>0.512241</td>\n",
              "      <td>0.433715</td>\n",
              "      <td>0.507693</td>\n",
              "      <td>0.299089</td>\n",
              "      <td>0.447958</td>\n",
              "      <td>0.425490</td>\n",
              "      <td>0.427266</td>\n",
              "      <td>0.262639</td>\n",
              "      <td>0.506685</td>\n",
              "      <td>0.435924</td>\n",
              "      <td>0.410349</td>\n",
              "      <td>0.476858</td>\n",
              "      <td>0.463900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.270865</td>\n",
              "      <td>0.471032</td>\n",
              "      <td>0.477136</td>\n",
              "      <td>0.393654</td>\n",
              "      <td>0.468545</td>\n",
              "      <td>0.392705</td>\n",
              "      <td>0.418159</td>\n",
              "      <td>0.392699</td>\n",
              "      <td>0.150807</td>\n",
              "      <td>0.371305</td>\n",
              "      <td>0.470058</td>\n",
              "      <td>0.382083</td>\n",
              "      <td>0.371613</td>\n",
              "      <td>0.451706</td>\n",
              "      <td>0.434965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.129637</td>\n",
              "      <td>0.407601</td>\n",
              "      <td>0.422208</td>\n",
              "      <td>0.332193</td>\n",
              "      <td>0.414372</td>\n",
              "      <td>0.316636</td>\n",
              "      <td>0.350791</td>\n",
              "      <td>0.276739</td>\n",
              "      <td>0.358744</td>\n",
              "      <td>0.275885</td>\n",
              "      <td>0.410634</td>\n",
              "      <td>0.315394</td>\n",
              "      <td>0.300338</td>\n",
              "      <td>0.398919</td>\n",
              "      <td>0.367578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.318109</td>\n",
              "      <td>0.503839</td>\n",
              "      <td>0.510207</td>\n",
              "      <td>0.402907</td>\n",
              "      <td>0.494484</td>\n",
              "      <td>0.410380</td>\n",
              "      <td>0.134430</td>\n",
              "      <td>0.427619</td>\n",
              "      <td>0.458188</td>\n",
              "      <td>0.360578</td>\n",
              "      <td>0.496030</td>\n",
              "      <td>0.424072</td>\n",
              "      <td>0.397136</td>\n",
              "      <td>0.487527</td>\n",
              "      <td>0.456718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.147730</td>\n",
              "      <td>0.405791</td>\n",
              "      <td>0.420199</td>\n",
              "      <td>0.295004</td>\n",
              "      <td>0.409420</td>\n",
              "      <td>0.301258</td>\n",
              "      <td>0.342247</td>\n",
              "      <td>0.312124</td>\n",
              "      <td>0.355722</td>\n",
              "      <td>0.299204</td>\n",
              "      <td>0.402431</td>\n",
              "      <td>0.136371</td>\n",
              "      <td>0.281426</td>\n",
              "      <td>0.389909</td>\n",
              "      <td>0.356471</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   DistanceTo1thCluster  DistanceTo2thCluster  DistanceTo3thCluster  \\\n",
              "0              0.333051              0.508755              0.512241   \n",
              "1              0.270865              0.471032              0.477136   \n",
              "2              0.129637              0.407601              0.422208   \n",
              "3              0.318109              0.503839              0.510207   \n",
              "4              0.147730              0.405791              0.420199   \n",
              "\n",
              "   DistanceTo4thCluster  DistanceTo5thCluster  DistanceTo6thCluster  \\\n",
              "0              0.433715              0.507693              0.299089   \n",
              "1              0.393654              0.468545              0.392705   \n",
              "2              0.332193              0.414372              0.316636   \n",
              "3              0.402907              0.494484              0.410380   \n",
              "4              0.295004              0.409420              0.301258   \n",
              "\n",
              "   DistanceTo7thCluster  DistanceTo8thCluster  DistanceTo9thCluster  \\\n",
              "0              0.447958              0.425490              0.427266   \n",
              "1              0.418159              0.392699              0.150807   \n",
              "2              0.350791              0.276739              0.358744   \n",
              "3              0.134430              0.427619              0.458188   \n",
              "4              0.342247              0.312124              0.355722   \n",
              "\n",
              "   DistanceTo10thCluster  DistanceTo11thCluster  DistanceTo12thCluster  \\\n",
              "0               0.262639               0.506685               0.435924   \n",
              "1               0.371305               0.470058               0.382083   \n",
              "2               0.275885               0.410634               0.315394   \n",
              "3               0.360578               0.496030               0.424072   \n",
              "4               0.299204               0.402431               0.136371   \n",
              "\n",
              "   DistanceTo13thCluster  DistanceTo14thCluster  DistanceTo15thCluster  \n",
              "0               0.410349               0.476858               0.463900  \n",
              "1               0.371613               0.451706               0.434965  \n",
              "2               0.300338               0.398919               0.367578  \n",
              "3               0.397136               0.487527               0.456718  \n",
              "4               0.281426               0.389909               0.356471  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=15, random_state=0)\n",
        "kmeans.fit(pca_train)\n",
        "\n",
        "dists_columns = ['DistanceTo1thCluster',\n",
        "                 'DistanceTo2thCluster',\n",
        "                 'DistanceTo3thCluster',\n",
        "                 'DistanceTo4thCluster',\n",
        "                 'DistanceTo5thCluster',\n",
        "                 'DistanceTo6thCluster',\n",
        "                 'DistanceTo7thCluster',\n",
        "                 'DistanceTo8thCluster',\n",
        "                 'DistanceTo9thCluster',\n",
        "                 'DistanceTo10thCluster',\n",
        "                 'DistanceTo11thCluster',\n",
        "                 'DistanceTo12thCluster',\n",
        "                 'DistanceTo13thCluster',\n",
        "                 'DistanceTo14thCluster',\n",
        "                 'DistanceTo15thCluster']\n",
        "\n",
        "dists_df_train = pd.DataFrame(\n",
        "    data=kmeans.transform(pca_train),\n",
        "    columns=dists_columns\n",
        ")\n",
        "\n",
        "dists_df_test = pd.DataFrame(\n",
        "    data=kmeans.transform(pca_test),\n",
        "    columns=dists_columns\n",
        ")\n",
        "\n",
        "dists_df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b69b833",
      "metadata": {
        "id": "6b69b833"
      },
      "source": [
        "Обучим SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9cb473",
      "metadata": {
        "id": "ef9cb473"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "SGD = SGDClassifier(max_iter=30000)\n",
        "\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "for alpha in np.linspace(1e-6, 1, 5):\n",
        "    SGD.set_params(**{'alpha': alpha})\n",
        "\n",
        "    SGD.fit(\n",
        "        dists_df_train,\n",
        "        df_train['tare']\n",
        "    )\n",
        "\n",
        "    train_preds = SGD.predict(dists_df_train)\n",
        "    train_accuracy = np.mean(train_preds == df_train[\"tare\"].values)\n",
        "    train_acc.append(train_accuracy)\n",
        "\n",
        "    test_preds = SGD.predict(dists_df_test)\n",
        "    test_accuracy = np.mean(test_preds == df_test[\"tare\"].values)\n",
        "    test_acc.append(test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8582dce8",
      "metadata": {
        "id": "8582dce8",
        "outputId": "860b79cd-ce5a-4e2a-baa1-0577ce1e30d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.39667388309387913,\n",
              " 0.37679590631765403,\n",
              " 0.29462704192088174,\n",
              " 0.35977169848455026,\n",
              " 0.2901003739421374]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e59f9ea",
      "metadata": {
        "id": "9e59f9ea",
        "outputId": "06b30f7b-47a2-49eb-faf1-e991d0dace7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.3964770714426294,\n",
              " 0.37554943252640555,\n",
              " 0.2960703273633799,\n",
              " 0.35763957226267795,\n",
              " 0.29292134094338385]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5388c4",
      "metadata": {
        "id": "5a5388c4"
      },
      "source": [
        "Качество сильно ухудшилось! Такое произошло вероятно из-за того, что алгоритм преобразования не подходит под наши данные."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5688395",
      "metadata": {
        "id": "b5688395"
      },
      "source": [
        "### Улучшим процедуру tf-idf преобразования: предварительный стемминг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a44f70",
      "metadata": {
        "id": "95a44f70"
      },
      "outputs": [],
      "source": [
        "from TextProcessing import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9882150b",
      "metadata": {
        "id": "9882150b"
      },
      "source": [
        "Взглянем на результат обработки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a187d2",
      "metadata": {
        "id": "15a187d2",
        "outputId": "e5c9c653-7166-4f46-e319-85ecaf1270b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                         Котлеты МЛМ из говядины 335г\n",
              "1    Победа Вкуса конфеты Мишки в лесу 250г(КФ ПОБЕ...\n",
              "2    ТВОРОГ (ЮНИМИЛК) \"ПРОСТОКВАШИНО\" ЗЕРНЕНЫЙ 130Г...\n",
              "3    Сыр Плавленый Веселый Молочник с Грибами 190г ...\n",
              "4      Жевательный мармелад Маша и медведь  буквы 100г\n",
              "Name: name, dtype: object"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"name\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967dc851",
      "metadata": {
        "id": "967dc851",
        "outputId": "6f0203e4-f733-4c2d-b84f-42bfdbdc2eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                         котлет млм из говядин 335г\n",
              "1     побед вкус конфет мишк в лес 250г кф побед  20\n",
              "2    творог  юнимилк   простоквашин  зернен 130гр 7 \n",
              "3         сыр плавлен весел молочник с гриб 190г ван\n",
              "4         жевательн мармелад маш и медвед  букв 100г\n",
              "Name: name, dtype: object"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"name\"].head().apply(preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf43dfb0",
      "metadata": {
        "id": "bf43dfb0"
      },
      "source": [
        "В ходе экспериментов данное преобразование никак не улучшило существующую модель."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2199e14",
      "metadata": {
        "id": "a2199e14"
      },
      "source": [
        "### В какую сторону можно искать улучшения?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b000f2",
      "metadata": {
        "id": "58b000f2"
      },
      "source": [
        "Во-первых, необходимо лучше обработать текст перед тем, как скармливать его `tf-idf`. Например, такие сущности как 400гр и 0.4кг можно преобразовать к единому формату, то же касается мер объема. Также некоторые названия могут писаться слитно, например, ?*КолбасаДокторская*. В таком случае `tf-idf` распознает это как отдельное уникальное слово, скорее непохожее на просто Колбасу.\n",
        "\n",
        "Во-вторых, можно продолжить эксперименты с моделями и посмотреть побольше в сторону ансамблей и метрических алгоритмов поверх tf-idf. Или сильнее и глубже поиграться с параметрами регуляризации того же SVM.\n",
        "\n",
        "Наконец, есть множество других способов классификации текстов: нейросетевой подход, LDA, etc."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}